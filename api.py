"""FastAPI application with LangServe for LangChain agent streaming."""

import logging
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from typing import Optional, Any
import uvicorn

from main import AgentApp
from routes import health_routes, agent_routes, config_routes
from services.telemetry import get_telemetry, TelemetryManager

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(), logging.FileHandler("api.log")],
)
logger = logging.getLogger(__name__)

# Suppress verbose third-party logs
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)

try:
    from langserve import add_routes

    LANGSERVE_AVAILABLE = True
except ImportError:
    LANGSERVE_AVAILABLE = False
    logger.warning("langserve not installed. Run: pip install langserve[all]")


# Initialize FastAPI app
app = FastAPI(
    title="LangChain Agent API",
    description="FastAPI backend for LangChain function calling agent with streaming support",
    version="1.0.0",
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize telemetry (self-hosted metrics)
telemetry: Optional[TelemetryManager] = None
try:
    telemetry = get_telemetry(
        service_name="chatbot-agent-api",
        metrics_port=9090,
        enable_metrics_server=True,
    )
    logger.info("‚úÖ Telemetry initialized")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è  Telemetry initialization failed: {e}")
    telemetry = None

# Initialize agent
agent_executor: Optional[Any] = None
agent_app: Optional[AgentApp] = None
try:
    logger.info("Initializing agent application...")
    agent_app = AgentApp(enable_sql_tool=False, llm_provider="openai")
    agent_executor = agent_app.agent_executor
    AGENT_LOADED = True
    logger.info("‚úÖ Agent loaded successfully")
except Exception as e:
    logger.error(f"‚ùå Error loading agent: {e}", exc_info=True)
    agent_executor = None
    agent_app = None
    AGENT_LOADED = False


# Configure route modules with agent state
health_routes.set_agent_state(agent_app, AGENT_LOADED, LANGSERVE_AVAILABLE)
agent_routes.set_agent_executor(agent_executor, AGENT_LOADED, telemetry)
config_routes.set_agent_app(agent_app, AGENT_LOADED)

# Register routers
app.include_router(health_routes.router)
app.include_router(agent_routes.router)
app.include_router(config_routes.router)


@app.get("/", tags=["Root"])
async def root():
    """Root endpoint."""
    return {
        "message": "LangChain Agent API",
        "docs": "/docs",
        "health": "/health",
        "agent_endpoint": "/agent" if LANGSERVE_AVAILABLE else "/query",
        "playground": "/agent/playground" if LANGSERVE_AVAILABLE else None,
        "metrics": "http://localhost:9090/metrics" if telemetry else None,
    }


# LangServe Routes (Recommended - with streaming support)
if LANGSERVE_AVAILABLE and agent_executor:
    add_routes(  # type: ignore
        app,
        agent_executor,
        path="/agent",
        # Let LangServe enable all endpoints by default for playground to work
        playground_type="default",  # Default playground works with LangGraph agents
        enable_feedback_endpoint=True,
    )
    print("‚úÖ LangServe routes added at /agent")
    print("üìä Playground available at http://localhost:8000/agent/playground")


# Error handlers
@app.exception_handler(404)
async def not_found_handler(request, exc):
    """Handle 404 errors."""
    return JSONResponse(
        status_code=404,
        content={"detail": "Endpoint not found. Check /docs for available endpoints."},
    )


@app.exception_handler(500)
async def internal_error_handler(request, exc):
    """Handle 500 errors."""
    return JSONResponse(
        status_code=500, content={"detail": "Internal server error. Check logs for details."}
    )


def main():
    """Run the FastAPI application."""
    print("\n" + "=" * 60)
    print("üöÄ Starting LangChain Agent API Server")
    print("=" * 60)
    print("üìç Server: http://localhost:8000")
    print("üìö API Docs: http://localhost:8000/docs")
    print("üîÑ ReDoc: http://localhost:8000/redoc")

    if LANGSERVE_AVAILABLE:
        print("üéÆ Playground: http://localhost:8000/agent/playground")
        print("üì° Streaming: POST http://localhost:8000/agent/stream")
    else:
        print("‚ö†Ô∏è  LangServe not available - install with: pip install langserve[all]")
        print("üì° Query endpoint: POST http://localhost:8000/query")

    print("=" * 60 + "\n")

    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
        access_log=True,
    )


if __name__ == "__main__":
    main()
